{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dHmqgA61xTi"
      },
      "outputs": [],
      "source": [
        "# Install various libraries using pip\n",
        "!pip install google-generativeai tiktoken PyPDF2 futures openai feedparser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import openai\n",
        "import tiktoken\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "5JPs4AfI4Ncb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key= userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        " # Call gemini 1.5 pro model\n",
        "def gemini(prompt, max_tokens):\n",
        "    gemini_model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "    response = gemini_model.generate_content(prompt, generation_config=genai.types.GenerationConfig(\n",
        "        max_output_tokens=max_tokens,\n",
        "        temperature=0.1,\n",
        "    ))\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "eO4rxNTP4QTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Call openai 4o model\n",
        "def openai_call(prompt,  max_tokens, temperature=0.1):\n",
        "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "  response = openai.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=messages,\n",
        "  temperature=temperature,\n",
        "  max_tokens=max_tokens,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  )\n",
        "  return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "Q8i8b4Y1rHLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMAIL = userdata.get(\"EMAIL\")\n",
        "\n",
        "# Call the citeas API for references\n",
        "def get_reference(doi):\n",
        "  url = f\"https://api.citeas.org/product/{doi}?email={EMAIL}\"\n",
        "  response = requests.get(url)\n",
        "\n",
        "  data = response.json()\n",
        "  try:\n",
        "    reference = data[\"citations\"][1][\"citation\"]\n",
        "  except:\n",
        "    reference = data[\"citations\"][0][\"citation\"]\n",
        "  reference = reference.replace(\"<i>\", \"\").replace(\"</i>\", \"\")\n",
        "  return reference"
      ],
      "metadata": {
        "id": "iYM7hjOIbXz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count input tokens\n",
        "def count_tokens(text):\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    tokens = encoding.encode(text)\n",
        "    return len(tokens)"
      ],
      "metadata": {
        "id": "P-E9Znh24m0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class BaseWebAPIDataLoader(ABC):\n",
        "    def __init__(self, base_url):\n",
        "        self.base_url = base_url\n",
        "\n",
        "    @abstractmethod\n",
        "    def fetch_data(self, search_query, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def make_request(self, endpoint, params=None, headers=None):\n",
        "        url = f\"{self.base_url}{endpoint}\"\n",
        "        response = requests.get(url, params=params, headers=headers)\n",
        "        print(url)\n",
        "        print(params)\n",
        "        print(headers)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            return data\n",
        "        else:\n",
        "            raise Exception(f\"Failed to fetch data from API: {response.status_code}\")"
      ],
      "metadata": {
        "id": "DDElFnftfQwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make intext-citations according to number of authors\n",
        "def get_intext_citation(reference):\n",
        "\n",
        "    authors_list = []\n",
        "    pattern = r'^(.*?)\\s*,\\s*(\\d{4})'\n",
        "    match = re.match(pattern, reference)\n",
        "    if match:\n",
        "        authors = match.group(1)\n",
        "        year = match.group(2)\n",
        "\n",
        "    if 'et al.,' in reference:\n",
        "        surname_index = reference.find(',')\n",
        "        surname = reference[:surname_index]\n",
        "        match = re.search(r'\\b\\d{4}\\b', reference)\n",
        "        if match:\n",
        "            year = match.group(0)\n",
        "        intext_citation = f\"{surname} et al. ({year})\"\n",
        "        return intext_citation\n",
        "\n",
        "    elif '.,' not in authors and '&' in authors:\n",
        "        authors_list = authors.split(\" & \")\n",
        "    elif '.,' not in authors and '&' not in authors:\n",
        "        authors_list = authors.split(\".,\")\n",
        "    else:\n",
        "        authors_list = re.split(r',\\s| & ', authors)\n",
        "\n",
        "    if len(authors_list) == 1:\n",
        "        surname = authors_list[0].split(\",\")\n",
        "        if \" \" in surname:\n",
        "            surname = surname.split(\" \")[1]\n",
        "        intext_citation = f\"{surname[0]} ({year})\"\n",
        "\n",
        "    elif len(authors_list) == 2:\n",
        "        author1_surname = authors_list[0].split(\",\")[0]\n",
        "        if \" \" in author1_surname:\n",
        "            author1_surname = author1_surname.split(\" \")[1]\n",
        "        author2_surname = authors_list[1].split(\",\")[0]\n",
        "        if \" \" in author2_surname:\n",
        "            author2_surname = author2_surname.split(\" \")[1]\n",
        "        intext_citation = f\"{author1_surname} and {author2_surname} ({year})\"\n",
        "\n",
        "    else:\n",
        "        surname = authors_list[0].split(\",\")[0]\n",
        "        intext_citation = f\"{surname} et al. ({year})\"\n",
        "\n",
        "    return intext_citation"
      ],
      "metadata": {
        "id": "lVAkNKGNYMtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jellyfish\n",
        "\n",
        "# Get research papers from semantic scholar\n",
        "class SemanticScholarLoader(BaseWebAPIDataLoader):\n",
        "    SS_key = None\n",
        "    def __init__(self,SS_key):\n",
        "        self.SS_key = SS_key\n",
        "        super().__init__(\"https://api.semanticscholar.org/graph/v1/paper/search\")\n",
        "\n",
        "    def fetch_data(self, search_query, limit=12, year_range=None):\n",
        "        headers = {\n",
        "            \"x-api-key\": self.SS_key\n",
        "        }\n",
        "        params = {\n",
        "            \"query\": search_query,\n",
        "            \"limit\": limit,\n",
        "            \"fields\": \"title,url,abstract,authors,citationStyles,journal,year,externalIds\",\n",
        "        }\n",
        "\n",
        "        if year_range is not None:\n",
        "            params[\"year\"] = year_range\n",
        "\n",
        "        data = self.make_request(\"\", params=params, headers=headers)\n",
        "        return data.get(\"data\", [])\n",
        "\n",
        "    def fetch_and_sort_papers(\n",
        "        self,\n",
        "        search_query,\n",
        "        limit=20,\n",
        "        top_n=20,\n",
        "        year_range=None,\n",
        "        weight_similarity=0.7,\n",
        "    ):\n",
        "        papers = []\n",
        "        abstracts = []\n",
        "        references = []\n",
        "        papers.extend(self.fetch_data(research_question, limit, year_range))\n",
        "\n",
        "        for paper in papers:\n",
        "          abstract = paper.get(\"abstract\", \"\")\n",
        "          try:\n",
        "            doi = paper[\"externalIds\"][\"DOI\"]\n",
        "          except:\n",
        "            doi = None\n",
        "\n",
        "          if abstract != None and doi != None:\n",
        "              reference = get_reference(doi)\n",
        "              if \"(n.d.).\" in reference and \"Error: DOI Not Found\" in reference:\n",
        "                continue\n",
        "              else:\n",
        "                intext_citation = get_intext_citation(reference)\n",
        "                references.append(reference)\n",
        "                abstract = f\"{abstract} in-text citations: {intext_citation}\"\n",
        "                abstracts.append(abstract)\n",
        "          else:\n",
        "            continue\n",
        "\n",
        "        return abstracts, references"
      ],
      "metadata": {
        "id": "IN_qH2cN6FKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "\n",
        "# Get research papers from arxiv\n",
        "def search_arxiv(query):\n",
        "    abstracts = []\n",
        "    references = []\n",
        "    base_url = \"http://export.arxiv.org/api/query?\"\n",
        "\n",
        "    query_params = {\n",
        "        \"search_query\": query,\n",
        "        \"max_results\": 10\n",
        "    }\n",
        "    response = requests.get(base_url, params=query_params)\n",
        "    feed = feedparser.parse(response.content)\n",
        "\n",
        "    for result in feed.entries:\n",
        "        arxiv_id = result.id\n",
        "        abstract = result.summary\n",
        "        if abstract != None and arxiv_id != None:\n",
        "              reference = get_reference(arxiv_id)\n",
        "              if \"(n.d.).\" in reference and \"Error: DOI Not Found\" in reference:\n",
        "                continue\n",
        "              else:\n",
        "                intext_citation = get_intext_citation(reference)\n",
        "                references.append(reference)\n",
        "                abstract = abstract.replace(\"\\n\", \"\")\n",
        "                abstract = f\"{abstract} in-text citations: {intext_citation}\"\n",
        "                abstracts.append(abstract)\n",
        "\n",
        "    return abstracts, references"
      ],
      "metadata": {
        "id": "wpt741mlqLdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# literature review prompt\n",
        "literature_review_prompt = \"\"\"\n",
        "Write a coherent literature review from all provided research papers while addressing the research question \"{research_question}\" for the purpose to help researchers in their research paper.\n",
        "Write professionally in a seamless flow. Must use all the provided research paper in the literature review. Add only one in-text citation per research paper from the attached intext_citations.\n",
        "Write at least a few sentences for every citation and research paper.\n",
        "\n",
        "Research Papers: {abstracts}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5TrXp5ek4_55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_literature_review(abstracts, research_question, model):\n",
        "    print(\"Writing literature review...\")\n",
        "    prompt = literature_review_prompt.format(research_question=research_question, abstracts=abstracts)\n",
        "\n",
        "    # Calculate the tokens in the input\n",
        "    input_tokens = count_tokens(prompt)\n",
        "    print(\"Input tokens:\", input_tokens)\n",
        "\n",
        "    remaining_tokens = 4080 - input_tokens\n",
        "    max_tokens = max(remaining_tokens, 0)\n",
        "\n",
        "    if max_tokens <= 0:\n",
        "      print(\"input tokens are greater than 4000 tokens.\")\n",
        "      return\n",
        "\n",
        "    if model == \"gemini-1.5-pro\":\n",
        "      literature_review_text = gemini(prompt, max_tokens=max_tokens)\n",
        "    else:\n",
        "      literature_review_text = openai_call(prompt, max_tokens=max_tokens)\n",
        "\n",
        "    return literature_review_text"
      ],
      "metadata": {
        "id": "lt5LF71a4c0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_list_into_3(lst):\n",
        "    n = len(lst)\n",
        "    avg = n // 3\n",
        "    remainder = n % 3\n",
        "\n",
        "    part1 = lst[:avg + (1 if remainder > 0 else 0)]\n",
        "    part2 = lst[len(part1):len(part1) + avg + (1 if remainder > 1 else 0)]\n",
        "    part3 = lst[len(part1) + len(part2):]\n",
        "\n",
        "    return part1, part2, part3"
      ],
      "metadata": {
        "id": "QTnVD0kzq1Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_literature_review(research_question, SS_key, model):\n",
        "    print(f\"Research question: {research_question}\")\n",
        "\n",
        "    abstracts = []\n",
        "    references = []\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "      arxiv = executor.submit(search_arxiv, research_question)\n",
        "      semantic_scholar = executor.submit(SemanticScholarLoader(SS_key).fetch_and_sort_papers, research_question)\n",
        "\n",
        "      try:\n",
        "        abstracts.extend(arxiv.result()[0])\n",
        "        references.extend(arxiv.result()[1])\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      try:\n",
        "        abstracts.extend(semantic_scholar.result()[0])\n",
        "        references.extend(semantic_scholar.result()[1])\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      print(f\"Number of abstracts: {len(abstracts)}\")\n",
        "      abstracts1, abstracts2, abstracts3 = split_list_into_3(abstracts)\n",
        "      print(f\"Number of abstracts 1: {len(abstracts1)}\")\n",
        "      print(f\"Number of abstracts 2: {len(abstracts2)}\")\n",
        "      print(f\"Number of abstracts 3: {len(abstracts3)}\")\n",
        "      print(abstracts3)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        future1 = executor.submit(write_literature_review, abstracts1, research_question, model)\n",
        "        future2 = executor.submit(write_literature_review, abstracts2, research_question, model)\n",
        "        future3 = executor.submit(write_literature_review, abstracts3, research_question, model)\n",
        "\n",
        "        literature_review1 = future1.result()\n",
        "        literature_review2 = future2.result()\n",
        "        literature_review3 = future3.result()\n",
        "\n",
        "        literature_review_text = literature_review1 + \" \" + literature_review2 + \" \" + literature_review3\n",
        "        print(f\"Literature Review: {literature_review_text}\")\n",
        "        references_list = \"\\n\".join([f\"{i}. {reference}\" for i, reference in enumerate(references, start=1)])\n",
        "        literature_review_text += f\"\\n\\nReferences: {references_list}\"\n",
        "\n",
        "        print(\"Literature Review:\", literature_review_text)\n",
        "\n",
        "    return literature_review_text"
      ],
      "metadata": {
        "id": "EScltoz82hRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your research question here\n",
        "research_question = input(\"Enter your research question: \")"
      ],
      "metadata": {
        "id": "HFn-g45i3nOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = input(\"1. gemini-1.5-pro \\n2. gpt-4o-mini \\n\\nEnter model: \")"
      ],
      "metadata": {
        "id": "gFQKCNjcprrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model == \"1\":\n",
        "  model = \"gemini-1.5-pro\"\n",
        "else:\n",
        "  model = \"gpt-4o-mini\""
      ],
      "metadata": {
        "id": "nRWRIUsLp2Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Semantic scholar API key\n",
        "SS_key = userdata.get(\"SS_key\")"
      ],
      "metadata": {
        "id": "385Y4bWY3lsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "literature_review = generate_literature_review(research_question, SS_key, model)"
      ],
      "metadata": {
        "id": "rjQqzlWHWEY2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}